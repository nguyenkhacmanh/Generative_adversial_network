{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important! Please do not remove any cells, including the test cells, even if they appear empty. They contain hidden tests, and deleting them could result in a loss of points, as the exercises are graded automatically. Only edit the cells where you are instructed to write your solution.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7256cddd9702ccef3d263d2b2d9ea907",
     "grade": false,
     "grade_id": "cell-97417793e2d30ab8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6: Generative Adversarial Network\n",
    "In this exercise, you will train a generative adversarial network (GAN) for **generaring images from random noise**\n",
    "\n",
    "GAN involves two neural network model: **generator** to generate fake images from noisy signal and **discriminator** to discriminate between the real and fake images.\n",
    "\n",
    "The dataset used in this exercise is the [MNIST](https://yann.lecun.com/exdb/mnist/), which contains of 60000 training images of handwritten digits, from 0 to 9 in grey scale color.\n",
    "\n",
    "#### Code template\n",
    "To complete this assignment, you will fill in the provided code template below. Your main tasks include:\n",
    "\n",
    "1. **Defining the Model (6 points)**\n",
    "2. **Setting the Loss Criterion and Optimizer (2 points)**\n",
    "3. **Writing the Training Loop (12 points)**\n",
    "\n",
    "Make sure to follow the instructions in the code template carefully and test your implementation before submission. If your code passes all the visible test cases, you get 50% of the points for each task. The remaining points are based on hidden test cases evaluated after submission.\n",
    "\n",
    "**Deliverables:** <br>\n",
    "\n",
    "Submit the completed notebook (ex6.ipynb) and your trained models (best_generator.pth and best_discriminator.pth) to moodle. \n",
    "Do not change the name of the notebook file. It may result in 0 points for the exercise.\n",
    "\n",
    "**Let's begin!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False   # You can set it to True if you want to run inference on your trained model. \n",
    "\n",
    "# Set the parameters\n",
    "# Do not change the noise size\n",
    "max_epochs = 20\n",
    "noise_size = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff8dcb2e3018a122838bab3834f95aa",
     "grade": true,
     "grade_id": "cell-5dd8c4dfa456eb1f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e2212e2d504b970bd1e78dfa825a582",
     "grade": false,
     "grade_id": "cell-a60636f38def2422",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>Import all the necessary libraries </h3>\n",
    "\n",
    "Firstl, we will import the essential libraries needed for building and training a deep learning model using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df4b644ac7c36dc72ced981a4e051979",
     "grade": false,
     "grade_id": "cell-2f8294eaa050f849",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3004bb2efe75d68c36ccdfc6d201faf3",
     "grade": false,
     "grade_id": "cell-cc4c633fe5e8a953",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Select the device the run the model.</h3>\n",
    "\n",
    "In this step, we will determine whether the model will run on a GPU (if available) or fall back to the CPU. Using a GPU for deep learning tasks can significantly speed up training, especially with large models or datasets.\n",
    "\n",
    "- `torch.device('cuda' if torch.cuda.is_available() else 'cpu')`: This checks for a CUDA-enabled GPU.\n",
    "  - If a GPU is available, it assigns `'cuda'` as the device.\n",
    "  - If no GPU is available, it defaults to the CPU (`'cpu'`).\n",
    "\n",
    "Make sure to always transfer both the model and the data to the selected dvice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "189b1d68b4ff420d0cbc7933f4c608aa",
     "grade": false,
     "grade_id": "cell-bde457a9a8b9968c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59f571f63613360de65efdfd4b047043",
     "grade": false,
     "grade_id": "cell-409946cfba91b5f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Download the dataset and create a dataloader to loop through mini batches of data. </h3>\n",
    "\n",
    "In this step, we will download and prepare the MNIST dataset, which consists of 28x28 pixel images of handwritten digits. We will split the dataset into a training set and a test set.\n",
    "\n",
    "- `MNIST`: Downloads the dataset and applies the transformation to \n",
    "  - resize the image to 32x32 pixel image\n",
    "  - transform the image to Tensor\n",
    "  - normalize the pixel values to [-1,1]\n",
    "- `train_size` and `test_size`: Specify the number of samples for the training and testing datasets, respectively. Here, we're using 4000 samples for training and 1000 for testing.\n",
    "- `random_split`: Randomly splits the dataset into the specified sizes for training and testing.\n",
    "- `DataLoader`: Loads the dataset into batches, making it easier to iterate through the dataset during training and testing. \n",
    "  - `batch_size=32`: Each batch will contain 32 images.\n",
    "  - `shuffle=True/False`: Randomly shuffles the dataset at each epoch to improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset_ex6' # you can change the path if you want to store the dataset somewhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ee2c81006dab01c44fa17b982b3ac18",
     "grade": true,
     "grade_id": "cell-fe5056e10e027184",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b8d75a2198a478d6beaec28c69a3ab3",
     "grade": false,
     "grade_id": "cell-bf9b45101256ed5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **2 - Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad7bc4fa2503c83efa58c852d5de2c89",
     "grade": false,
     "grade_id": "cell-8c5b82526974b1bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### Creating Pytorch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccdf11a32d954716e5a2976ef782e4b1",
     "grade": false,
     "grade_id": "cell-c1789af352f91149",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#MNIST dataset\n",
    "transform = transforms.Compose([transforms.Resize(32),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "dataset = MNIST(root=dataset_path, \n",
    "                train=True,\n",
    "                transform=transform,\n",
    "                download=True,)\n",
    "\n",
    "train_size = 0.8\n",
    "test_size = 0.2\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3c79a938d9ce96e276e2f56b8b395ec",
     "grade": false,
     "grade_id": "cell-571673aed935591f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>Visualizing data</h3>\n",
    "\n",
    "The following code block visualizes the some of the images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff2508ef6b3bf47b53d445f30d026a0e",
     "grade": false,
     "grade_id": "cell-c3cc35f7da39365b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "batch, _ = next(iter(train_loader))\n",
    "displayed_images = batch[:6].squeeze(1)\n",
    "fig, ax = plt.subplots(1, 6, figsize=(12, 4))\n",
    "\n",
    "for i in range(6):\n",
    "    ax[i].imshow(displayed_images[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "\n",
    "print(f\"Batch shape: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ca81ffaf57371768d499da3fea6d63a",
     "grade": false,
     "grade_id": "cell-53f5ca7d5f4ab24f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>Task 1: Define the Model classes <b> (6 points) </b>. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9422602a49ddce3b336ba74e99c558b5",
     "grade": false,
     "grade_id": "cell-e75b241f0474abd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h4>Task 1.1: Define the Discriminator class <b> (3 points) </b></h4>\n",
    "Your task is implementing a discriminator according to the architecture shown below. The dicriminator takes the image as the model input and output the predicting probability of the image being real image.\n",
    "\n",
    "**Your Task:**\n",
    "- Initialize all the layers in the `__init__` method.\n",
    "- Complete the `forward` method to pass the input through the layers in accordance with the architecture.\n",
    "- The order of the layers within a block is : Conv2D -> BatchNorm -> Activation layer\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"disc.png\" style=\"width:800px; height:auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc5c056c6ba8df233fb4793a5960f2a4",
     "grade": false,
     "grade_id": "cell-08fbd857057d1dd8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, \n",
    "                x:torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ace5ee0ec7bfec86b81fec04d726c3f8",
     "grade": false,
     "grade_id": "cell-97a063becff7f2de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Test the correctness of your model by running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56c96889514a5c5351c42d41dd43dd0e",
     "grade": true,
     "grade_id": "cell-4edb40ce4e48dcb7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test the model definition\n",
    "all_tests_successful = True\n",
    "conv2d_count, bn2d_count = 0, 0\n",
    "\n",
    "test_discriminator = Discriminator()\n",
    "for layer in test_discriminator.modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        conv2d_count += 1\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        bn2d_count += 1\n",
    "\n",
    "dummy_input = torch.randn(4,1,32,32)\n",
    "dummy_output = test_discriminator(dummy_input)\n",
    "\n",
    "if dummy_output.shape != (4,1):\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected output shape (4,1), instead got {dummy_output.shape}.\")\n",
    "\n",
    "if conv2d_count != 4:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected 4 Conv2d layers, got {conv2d_count}.\")\n",
    "\n",
    "if bn2d_count != 3:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected 3 BatchNorm2d layers, got {bn2d_count}.\")\n",
    "\n",
    "if all_tests_successful: \n",
    "    success_str = \"Good job! All visible tests passed! You can proceed further.\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c461ee6bd13c91f3817c017810ce3b4",
     "grade": true,
     "grade_id": "cell-9b4fc79e7d5d0689",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7b9cd2c427a82a282d14747137c44e0",
     "grade": false,
     "grade_id": "cell-ec2526d709147378",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h4>Task 1.2: Define the Generator class <b> (3 points) </b></h4>\n",
    "Your task is implementing a Generator according to the architecture shown below. The Generator takes the noise the model input and output the fake image.\n",
    "\n",
    "**Your Task:**\n",
    "- Initialize all the layers in the `__init__` method.\n",
    "- Complete the `forward` method to pass the input through the layers in accordance with the architecture.\n",
    "- - The order of the layers within a block is : ConvTransposed2D -> BatchNorm -> Activation layer\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"gen.png\" style=\"width:800px; height:auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8582b95464d90c0d108ca30c94fb2306",
     "grade": false,
     "grade_id": "cell-d537a2c488a09c68",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 noise_size:int,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self,\n",
    "                x:torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcded188fb270f619acfb44bcf83ac6f",
     "grade": false,
     "grade_id": "cell-7eacc0ccc5b2852e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Test the correctness of your model by running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3b1415d778dc6dda5f27252a67a6016",
     "grade": true,
     "grade_id": "cell-bde1a8ebf78d69a8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test the model definition\n",
    "all_tests_successful = True\n",
    "upconv2d_count, bn2d_count = 0, 0\n",
    "\n",
    "test_generator = Generator(100)\n",
    "for layer in test_generator.modules():\n",
    "    if isinstance(layer, nn.ConvTranspose2d):\n",
    "        upconv2d_count += 1\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        bn2d_count += 1\n",
    "\n",
    "dummy_input = torch.randn(4,100,1,1)\n",
    "dummy_output = test_generator(dummy_input)\n",
    "\n",
    "if dummy_output.shape != (4,1,32,32):\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected output shape (4,1,32,32), instead got {dummy_output.shape}.\")\n",
    "if upconv2d_count != 4:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected 4 ConvTranspose2d layers, got {upconv2d_count}.\")\n",
    "if bn2d_count != 3:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected 3 BatchNorm2d layers, got {bn2d_count}.\")\n",
    "if all_tests_successful:\n",
    "    success_str = \"Good job! All visible tests passed! You can proceed further.\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b26958882bbfebc422c6cce3f63097d",
     "grade": true,
     "grade_id": "cell-b2d3a9736b43b789",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7fe5a66e4b3cd358be71ac3fcb57fca",
     "grade": false,
     "grade_id": "cell-0807e89bcfface2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Task 2: Define the loss function and optimizer. <b> (2 Points) </b></h3>\n",
    "\n",
    "You will implement the `loss_and_optimizer` function, which is essential for training your network. Follow these guidelines to complete this function: <br>\n",
    "\n",
    "1. **Choose the Loss Function**: <br>\n",
    "   - This exercise involves the discriminator loss given real and fake images.<br>\n",
    "      - Generator tries to create fake images that fool the dicriminator.<br>\n",
    "      - Discriminator tries to correctly discriminate between real and fake images.<br>\n",
    "   - Since the discriminator performs a classification task with 2 labels: real and fake image, Binary Cross Entropy loss is chosen for this task<br>\n",
    "\n",
    "2. **Select the Optimizer**: <br>\n",
    "   - An optimizer is used to update the model parameters based on the loss function. <br>\n",
    "   - The Adam optimizer is widely used for its efficiency and effectiveness in handling large datasets and complex models. Initialize the Adam optimizers for both the generator and discriminator and set the learning rate to 0.0002 to control the step size during optimization.<br>\n",
    "\n",
    "3. **Return the components**: <br>\n",
    "   - Your function should return the loss criterion and the optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f596d70e0c20a9f325b132e72b2d0f46",
     "grade": false,
     "grade_id": "cell-eb0fe9253b1eb4b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def loss_and_optimizer(generator:Generator, \n",
    "                       discriminator:Discriminator) -> tuple:\n",
    "    \"\"\"Get loss function and optimizers for the generator and discriminator.\n",
    "\n",
    "    :param generator: Generator model\n",
    "    :type generator: Generator\n",
    "    :param discriminator: Discriminator model\n",
    "    :type discriminator: Discriminator\n",
    "    :return: Loss function, generator optimizer, discriminator optimizer\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return criterion, g_optimizer, d_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e0a4df546569b3f34f3ee49610774ca",
     "grade": false,
     "grade_id": "cell-bf5436f61a0c869e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator(noise_size).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion, g_optimizer, d_optimizer = loss_and_optimizer(generator, discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "972c8732dc2e5c6d5393cadff2a2f14a",
     "grade": false,
     "grade_id": "cell-57f7ce64068cb4ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Test the correctness of your loss_and_optimizer function by running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ed118523758ee7376d35a242b303be",
     "grade": true,
     "grade_id": "cell-27b7bf5b33be5252",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the correctness of loss function and optimizer \n",
    "all_tests_successful = True\n",
    "\n",
    "if not isinstance(criterion, nn.BCELoss):\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(\"The criterion is not set properly to BCE loss.\")\n",
    "\n",
    "for model, optimizer in zip([generator, discriminator], [g_optimizer, d_optimizer]):\n",
    "    model_params = list(model.parameters())\n",
    "    optimizer_params = [param for param_group in optimizer.param_groups for param in param_group['params']]\n",
    "    if model_params != optimizer_params:\n",
    "        all_tests_successful = False\n",
    "        raise AssertionError(\"The optimizer does not contain the model parameters\")\n",
    "\n",
    "if all_tests_successful:\n",
    "    success_str = \"Good job! All visible tests passed!\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97bcdc6fa0139ff4ffc5185f09fc29ff",
     "grade": true,
     "grade_id": "cell-570f3a7cf9f62f23",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cba465356cd945f72675e2e4b9a653d0",
     "grade": false,
     "grade_id": "cell-0069546c71effe4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Task 3: Training loop. <b>(12 points)</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b6abbbfebf30f85316575f1847b7d69",
     "grade": false,
     "grade_id": "cell-1f58ffc6d94dd731",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h4>Task 3.1: Define discriminator loss <b>(4 points)</b></h4>\n",
    "\n",
    "The discriminator objective is to correctly classify the images into real and fake. <br>\n",
    "\n",
    "Steps in calculating discriminator loss: <br>\n",
    "1) Create the correspoding labels for the real and fake images <br>\n",
    "    - Real labels should be all ones <br>\n",
    "    - Fake labels should be all zeros<br>\n",
    "2) Create fake images using the generator given the input noise.<br>\n",
    "    **Important**: Detach the fake images from the generator output using `.detach()` so that the gradients are not passed back to the generator.\n",
    "3) Compute the discriminator output and loss for the fake images.<br>\n",
    "The labels for the fake images should be all zeros.<br>\n",
    "4) Compute the discriminator output and loss for the real images.<br>\n",
    "The labels for the real images should be all ones.<br>\n",
    "5) Return the sum of the losses for the real and fake images.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4cb5a3de2e5147410b08da04ee79d53",
     "grade": false,
     "grade_id": "cell-27c34ab234a044c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forward_discriminator(generator: Generator,\n",
    "                           discriminator: Discriminator,\n",
    "                           criterion: nn.Module,\n",
    "                           real_images: torch.Tensor,\n",
    "                           noise: torch.Tensor,\n",
    "                           device: torch.device) -> tuple:\n",
    "    \"\"\"Forward pass for the discriminator.\n",
    "\n",
    "    :param generator: Generator model\n",
    "    :type generator: Generator\n",
    "    :param discriminator: Discriminator model\n",
    "    :type discriminator: Discriminator\n",
    "    :param criterion: Loss function\n",
    "    :type criterion: nn.Module\n",
    "    :param real_images: Real images\n",
    "    :type real_images: torch.Tensor\n",
    "    :param noise: Noise vector\n",
    "    :type noise: torch.Tensor\n",
    "    :param device: Device (cuda or cpu)\n",
    "    :type device: torch.device\n",
    "    :return: Loss, real labels, fake labels (labels are returned for testing purposes)\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87770987a0dcc4454ead1027c4cebfec",
     "grade": false,
     "grade_id": "cell-bfab7dcd1e539a60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Test the correctness of your function by running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4deb9f6452cf4716f2c18b767b15efa",
     "grade": true,
     "grade_id": "cell-3d4d06adb9490c37",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "all_tests_successful = True\n",
    "\n",
    "# Dummy variables for testing. DO NOT CHANGE!\n",
    "dummy_real_images = torch.ones(4, 1, 32, 32).to(device)\n",
    "dummy_noise = torch.randn(4, 100, 1, 1).to(device)\n",
    "\n",
    "gen = Generator(noise_size=100).to(device)\n",
    "disc = Discriminator().to(device)\n",
    "    \n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=0.0002)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=0.0002)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "loss, _, _ = forward_discriminator(gen, disc, criterion, dummy_real_images, dummy_noise, device)\n",
    "if loss.item() <= 0:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected loss > 0, got {loss.item()}\")\n",
    "\n",
    "if all_tests_successful:\n",
    "    success_str = \"Good job! All visible tests passed!\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bb1e5db16fa36c7f385eef8b2fa9429",
     "grade": true,
     "grade_id": "cell-9f73573799b0ad0c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0acb9f39eb838917bded2fe0924199b5",
     "grade": false,
     "grade_id": "cell-b08153c5c226c9a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h4>Task 3.2: Define generator loss </b>(4 points)</b></h4>\n",
    "\n",
    "The generator objective is to create fake images that can fool the discriminator <br>\n",
    "\n",
    "Steps in calculating discriminator loss: <br>\n",
    "1) Create fake images using the generator given the input noise. <br>\n",
    "2) Create the labels for the and fake images. To fool the discriminator, the labels should be all ones. <br>\n",
    "3) Compute the discriminator output given the fake images and loss <br>\n",
    "4) Return the loss. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c3c54788b89b638fccd0865dd7512c1",
     "grade": false,
     "grade_id": "cell-332ae13ea50a46f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forward_generator(generator: Generator,\n",
    "                        discriminator: Discriminator,\n",
    "                        criterion: nn.Module,\n",
    "                        noise: torch.Tensor,\n",
    "                        device: torch.device) -> tuple:\n",
    "    \"\"\"Forward pass for the generator.\n",
    "\n",
    "    :param generator: Generator model\n",
    "    :type generator: Generator\n",
    "    :param discriminator: Discriminator model\n",
    "    :type discriminator: Discriminator\n",
    "    :param criterion: Loss function\n",
    "    :type criterion: nn.Module\n",
    "    :param noise: Noise vector\n",
    "    :type noise: torch.Tensor\n",
    "    :param device: Device (cuda or cpu)\n",
    "    :type device: torch.device\n",
    "    :return: Loss, labels (labels are returned for testing purposes)\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22d7a4e9d0d80e8bfa4d5bab43b2f871",
     "grade": false,
     "grade_id": "cell-3dc569f474291fd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Test the correctness of your function by running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97a71a91fea6f805cee54437f1463e11",
     "grade": true,
     "grade_id": "cell-04a6f9f7a06ffb3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "all_tests_successful = True\n",
    "\n",
    "dummy_noise = torch.randn(4, 100, 1, 1).to(device)\n",
    "\n",
    "loss, labels = forward_generator(gen, disc, criterion, dummy_noise, device)\n",
    "if loss.item() <= 0:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected loss > 0, got {loss.item()}\")\n",
    "\n",
    "if all_tests_successful:\n",
    "    success_str = \"Good job! All visible tests passed!\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46c8c2c12ee048a780a6106abbf4de5f",
     "grade": true,
     "grade_id": "cell-73d816445c10b34f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96664221d0d631f09758020ed58d6d3c",
     "grade": false,
     "grade_id": "cell-b61f6db20f03e1e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h4>Task 3.3: Define training loop </b>(4 points)</b></h4>\n",
    "\n",
    "After having the functions to calculate the losses for GAN, we will implement the training loop for our GAN model. The training loop is where the model learns from the training data by adjusting its weights based on the loss function. <br>\n",
    "\n",
    "Your task is to implement the code template below. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db4f2c51be9bedb10f2d478d9b606017",
     "grade": false,
     "grade_id": "cell-bc2cd814a46e2c3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_img = torch.randn(64, 100, 1, 1).to(device) # fixed noise for visualization during training\n",
    "\n",
    "def train_gan(generator: Generator,\n",
    "              discriminator: Discriminator,\n",
    "              g_optimizer: torch.optim.Optimizer,\n",
    "              d_optimizer: torch.optim.Optimizer,\n",
    "              train_dataloader: DataLoader,\n",
    "              noise_size: torch.Tensor,\n",
    "              loss: nn.Module,\n",
    "              device: torch.device,\n",
    "              max_epochs: int = 20,\n",
    "              verbose: bool = True) -> tuple:\n",
    "    \"\"\"Train the GAN model.\n",
    "\n",
    "    :param generator: Generator model\n",
    "    :type generator: Generator\n",
    "    :param discriminator: Discriminator model\n",
    "    :type discriminator: Discriminator\n",
    "    :param g_optimizer: Generator optimizer\n",
    "    :type g_optimizer: torch.optim.Optimizer\n",
    "    :param d_optimizer: Discriminator optimizer\n",
    "    :type d_optimizer: torch.optim.Optimizer\n",
    "    :param train_dataloader: Training dataloader\n",
    "    :type train_dataloader: DataLoader\n",
    "    :param noise_size: Noise vector size\n",
    "    :type noise_size: torch.Tensor\n",
    "    :param loss: Loss function\n",
    "    :type loss: nn.Module\n",
    "    :param device: Device (cuda or cpu)\n",
    "    :type device: torch.device\n",
    "    :param max_epochs: Max number of training epochs, defaults to 20\n",
    "    :type max_epochs: int, optional\n",
    "    :param verbose: Printing out training process?, defaults to True\n",
    "    :type verbose: bool, optional\n",
    "    :return: Generator losses, Discriminator losses\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        generator_batch_losses = []\n",
    "        discriminator_batch_losses = []\n",
    "        for i, (real_images, _) in enumerate(train_dataloader):\n",
    "\n",
    "            # Move the images to the device (~ 1 line)\n",
    "            # Create the noise vector of size (batch_size, noise_size, 1, 1) (~ 1 line)\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "            # Train the discriminator (~ 4 lines)\n",
    "            # This step includes zeroing the gradients, forward pass, backward pass, and optimizer step\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "            # Train the generator (~ 4 lines)\n",
    "            # This step includes zeroing the gradients, forward pass, backward pass, and optimizer step\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "            generator_batch_losses.append(g_loss.item())\n",
    "            discriminator_batch_losses.append(d_loss.item())\n",
    "\n",
    "        # Visualize the generated images during training on fixed noise\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch}: Generator loss: {np.mean(generator_batch_losses):.2f}. Discriminator loss: {np.mean(discriminator_batch_losses):2f}\")\n",
    "            if epoch % 5 == 0:\n",
    "                sample_gen_imgs_in_train = generator(test_img).detach().cpu().squeeze()\n",
    "                nrow, ncols = 1, 5\n",
    "                fig, axes = plt.subplots(nrows=nrow,ncols=ncols, figsize=(6,1.5))\n",
    "                plt.suptitle(f'Epoch : {epoch}')\n",
    "                for ncol in range(ncols):\n",
    "                    axes[ncol].imshow(sample_gen_imgs_in_train[ncol], cmap='gray')\n",
    "                    axes[ncol].axis('off')\n",
    "                plt.show()\n",
    "        \n",
    "        generator_losses.append(np.mean(generator_batch_losses))\n",
    "        discriminator_losses.append(np.mean(discriminator_batch_losses))\n",
    "\n",
    "    return generator_losses, discriminator_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "688f61f4a39e9241c80d728c40b1ad31",
     "grade": true,
     "grade_id": "cell-facc463cf1ae7c85",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the training code\n",
    "all_tests_successful = True\n",
    "\n",
    "from unittest.mock import patch, MagicMock\n",
    "mock_train_loader = MagicMock()\n",
    "mock_train_loader.__iter__.return_value = [(torch.rand(1, 1, 32, 32), None)]\n",
    "\n",
    "with patch('torch.Tensor.backward') as mock_backward, \\\n",
    "     patch.object(gen_opt, 'step') as mock_g_step, \\\n",
    "     patch.object(disc_opt, 'step') as mock_d_step:\n",
    "    \n",
    "    train_gan(gen, disc, gen_opt, disc_opt, mock_train_loader, noise_size, criterion, device, max_epochs=1, verbose=False)\n",
    "\n",
    "    if mock_backward.call_count == 2:\n",
    "        pass\n",
    "    else:\n",
    "        all_tests_successful = False\n",
    "        raise AssertionError(\"You forgot to calculate the gradients for both models.\")\n",
    "    \n",
    "    if mock_g_step.called:\n",
    "        pass\n",
    "    else:\n",
    "        all_tests_successful = False\n",
    "        raise AssertionError(\"You forgot to update the weights of generator.\")\n",
    "    if mock_d_step.called:\n",
    "        pass\n",
    "    else:\n",
    "        all_tests_successful = False\n",
    "        raise AssertionError(\"You forgot to update the weights of dicriminator.\")\n",
    "    \n",
    "if all_tests_successful:\n",
    "    success_str = 'Good job! you can now proceed to train your model.'\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b04ef7f71402d3fd10492e9df56c2711",
     "grade": true,
     "grade_id": "cell-8a2c7c0878dc712d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca87a5cc041ff4b9a221c440ae9a954b",
     "grade": false,
     "grade_id": "cell-3cdf9e8e702826d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator(noise_size).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "if not skip_training:\n",
    "    criterion, g_optimizer, d_optimizer = loss_and_optimizer(generator, discriminator)\n",
    "    gen_losses, disc_losses = train_gan(generator, discriminator, g_optimizer, d_optimizer, train_loader, noise_size, criterion, device, max_epochs=max_epochs, verbose=True)\n",
    "    torch.save(generator.state_dict(), 'best_generator.pth')\n",
    "    torch.save(discriminator.state_dict(), 'best_discriminator.pth')\n",
    "    print(\"Your trained model is saved successfully!\")\n",
    "else:\n",
    "    generator.load_state_dict(torch.load('best_generator.pth', map_location=device))\n",
    "    discriminator.load_state_dict(torch.load('best_discriminator.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c066b744b988c0a52283dcbb0cf1621",
     "grade": false,
     "grade_id": "cell-b3eb9d7a18028b91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_img = torch.randn(64, 100, 1, 1).to(device)\n",
    "sample_gen_imgs_in_train = generator(test_img).detach().cpu().squeeze()\n",
    "nrow, ncols = 1, 10\n",
    "fig, axes = plt.subplots(nrows=nrow,ncols=ncols, figsize=(10,1.5))\n",
    "for ncol in range(ncols):\n",
    "    axes[ncol].imshow(sample_gen_imgs_in_train[ncol], cmap='gray')\n",
    "    axes[ncol].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
